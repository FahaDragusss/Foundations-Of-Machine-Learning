{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1</td>\n",
       "      <td>1.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1</td>\n",
       "      <td>1.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>1</td>\n",
       "      <td>2.3886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X0  median_income\n",
       "0       1         8.3252\n",
       "1       1         8.3014\n",
       "2       1         7.2574\n",
       "3       1         5.6431\n",
       "4       1         3.8462\n",
       "...    ..            ...\n",
       "20635   1         1.5603\n",
       "20636   1         2.5568\n",
       "20637   1         1.7000\n",
       "20638   1         1.8672\n",
       "20639   1         2.3886\n",
       "\n",
       "[20640 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pre-processing the Data\n",
    "\n",
    "house_df = pd.read_csv('california_house_dataset_handled.csv')\n",
    "# X = house_df.drop('median_house_value', axis=1)  #Feature\n",
    "X = house_df[['X0','median_income']]\n",
    "y = house_df['median_house_value'] #Target\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data for testing and training\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Scaling the Features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train.iloc[:, 1:] = scaler.fit_transform(X_train.iloc[:, 1:])  # Only scale the features, exclude X0 and other hot coded data\n",
    "X_test.iloc[:, 1:] = scaler.transform(X_test.iloc[:, 1:])  # Same for test data\n",
    "\n",
    "# Converting to Numpy Array\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train = X_train.to_numpy()\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    X_test = X_test.to_numpy()  \n",
    "\n",
    "# Initializing theta\n",
    "\n",
    "theta = np.random.randn(X.shape[1])*0.01 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtions\n",
    "\n",
    "def cost_function(y_pred, y_test_or_train):\n",
    "    m = len(y_pred)\n",
    "    sum = 0\n",
    "    y = y_test_or_train.to_numpy()\n",
    "    for i in range(m):\n",
    "        sum += ( y_pred[i] - y[i] )**2\n",
    "    return ( 1 / (2 * m) ) * sum\n",
    "\n",
    "def batch_gradient_descent(theta, X_train, y_train, lr):\n",
    "    m = len(y_train)\n",
    "    y_train = y_train.to_numpy()  # Ensure y_train is a NumPy array\n",
    "    y_pred = np.dot(X_train, theta)  # Predictions\n",
    "\n",
    "    for j in range(len(theta)):  # Iterate over all parameters (features)\n",
    "        sum_grad = 0\n",
    "        for i in range(m):  # Iterate over all data points\n",
    "            # Correct the gradient: (y_pred - y_train) instead of (y_train - y_pred)\n",
    "            sum_grad += (y_pred[i] - y_train[i]) * X_train[i, j]\n",
    "        theta[j] = theta[j] - (lr * sum_grad) / m  # Update theta[j]\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28148709549.946438\n",
      "19273634602.598534\n",
      "13593586636.295979\n",
      "9958355937.862362\n",
      "7631808290.864765\n",
      "6142817796.786337\n",
      "5189863880.576167\n",
      "4579973374.20167\n",
      "4189643450.1219783\n",
      "3939832298.7109895\n",
      "3779953161.8079343\n",
      "3677630514.189991\n",
      "3612144019.714505\n",
      "3570232663.2502065\n",
      "3543409395.1130357\n",
      "3526242503.505245\n",
      "3515255692.8762627\n",
      "3508224134.073726\n",
      "3503723936.4400926\n",
      "3500843809.9545608\n",
      "3499000529.0038457\n",
      "3497820829.195357\n",
      "3497065821.31794\n",
      "3496582616.276399\n",
      "3496273365.049815\n",
      "3496075444.264796\n",
      "3495948774.9623613\n",
      "3495867706.6088233\n",
      "3495815822.8625627\n",
      "3495782617.264964\n",
      "3495761365.682471\n",
      "3495747764.669689\n",
      "3495739060.0215015\n",
      "3495733489.046681\n",
      "3495729923.6227813\n",
      "3495727641.751497\n",
      "3495726181.353876\n",
      "3495725246.6993876\n",
      "3495724648.520498\n",
      "3495724265.6860375\n",
      "3495724020.6719847\n",
      "3495723863.862975\n",
      "3495723763.505218\n",
      "3495723699.2762556\n",
      "3495723658.169708\n",
      "3495723631.861524\n",
      "3495723615.024257\n",
      "3495723604.2484503\n",
      "3495723597.3519263\n",
      "3495723592.9381094\n",
      "3495723590.113328\n",
      "3495723588.3054376\n",
      "3495723587.148373\n",
      "3495723586.4079027\n",
      "3495723585.933962\n",
      "3495723585.630643\n",
      "3495723585.436524\n",
      "3495723585.312287\n",
      "3495723585.2327533\n",
      "3495723585.1818833\n",
      "3495723585.149316\n",
      "3495723585.128445\n",
      "3495723585.115135\n",
      "3495723585.1065845\n",
      "3495723585.101142\n",
      "3495723585.0976324\n",
      "3495723585.095375\n",
      "3495723585.093958\n",
      "3495723585.093037\n",
      "3495723585.0924473\n",
      "3495723585.0920606\n",
      "3495723585.0918503\n",
      "3495723585.091696\n",
      "3495723585.0915875\n",
      "3495723585.091518\n",
      "3495723585.091497\n",
      "3495723585.091462\n",
      "3495723585.09145\n",
      "3495723585.091412\n",
      "3495723585.0914235\n",
      "3495723585.0914125\n",
      "3495723585.091422\n",
      "3495723585.091412\n",
      "3495723585.091425\n",
      "3495723585.091419\n",
      "3495723585.0914087\n",
      "3495723585.091401\n",
      "3495723585.0913916\n",
      "3495723585.0914183\n",
      "3495723585.0914044\n",
      "3495723585.0914125\n",
      "3495723585.09142\n",
      "3495723585.0914125\n",
      "3495723585.0914187\n",
      "3495723585.091398\n",
      "3495723585.091433\n",
      "3495723585.091411\n",
      "3495723585.091409\n",
      "3495723585.0914006\n",
      "3495723585.0914106\n",
      "3495723585.091392\n",
      "3495723585.091397\n",
      "3495723585.091411\n",
      "3495723585.0914125\n",
      "3495723585.0914254\n",
      "3495723585.0914044\n",
      "3495723585.0914054\n",
      "Converged in  106  iterations\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "tolerance = 1e-6 # Convergence thershold\n",
    "previous_cost = float('inf')\n",
    "alpha = 0.2\n",
    "iteration = 0\n",
    "cost_history = []\n",
    "theta_history = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    if iteration >= 10000:\n",
    "        break\n",
    "    \n",
    "    y_pred = np.dot(X_train , theta)  \n",
    "    cost = cost_function(y_pred, y_train)\n",
    "    print(cost)\n",
    "    \n",
    "    if abs(previous_cost - cost) < tolerance:  \n",
    "        break  \n",
    "\n",
    "    theta = batch_gradient_descent(theta, X_train, y_train, alpha)  \n",
    "    previous_cost = cost  \n",
    "    iteration += 1\n",
    "\n",
    "    if iteration % 100 == 0:  \n",
    "       cost_history.append(cost)\n",
    "       theta_history.append(theta.copy())\n",
    "print(\"Converged in \",iteration,\" iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Functions\n",
    "\n",
    "def mean_absolute_error(y_pred , y_test_or_train):\n",
    "    m = len(y_pred)\n",
    "    sum = 0\n",
    "    y = y_test_or_train.values\n",
    "    for i in range(m):\n",
    "        sum += np.abs( y_pred[i] - y[i] )\n",
    "    return (1/m) * sum\n",
    "\n",
    "def mean_squared_error(y_pred, y_test_or_train):\n",
    "    m = len(y_pred)\n",
    "    sum = 0\n",
    "    y = y_test_or_train.values\n",
    "    for i in range(m):\n",
    "        sum += ( y_pred[i] - y[i] )**2\n",
    "    return ( 1 / m ) * sum\n",
    "\n",
    "def r2_score(y_pred , y_test_or_train):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    sum = 0\n",
    "    m = len(y_pred)\n",
    "    y = y_test_or_train.values\n",
    "\n",
    "    for i in range(m):\n",
    "        sum += y[i]\n",
    "        numerator += (y_pred[i] - y[i])**2\n",
    "    mean = sum/m\n",
    "\n",
    "    for i in range(m):\n",
    "        denominator += (y[i] - mean)**2\n",
    "    \n",
    "    return 1 - (numerator/denominator)\n",
    "\n",
    "def root_mean_squared_error(mse):\n",
    "    return mse**0.5\n",
    "\n",
    "y_predictions = np.dot(X_test , theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost :  3545578885.8817515\n",
      "Mean squared error :  7091157771.763503\n",
      "Root mean squared error :  84209.01241413239\n",
      "Mean absolute error :  62990.865298953504\n",
      "R2 score :  -0.4454217559103968\n",
      "These are the model predictions :  [114958.91676382 150606.88213159 190393.71843432 ... 431500.77228105\n",
      " 161245.49972224 193412.95559051]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "print(f\"Cost : \", cost_function(y_predictions,y_test))\n",
    "print(f\"Mean squared error : \", mean_squared_error(y_predictions,y_test))\n",
    "print(f\"Root mean squared error : \", root_mean_squared_error(mean_squared_error(y_predictions,y_test)))\n",
    "print(f\"Mean absolute error : \", mean_absolute_error(y_predictions,y_test))\n",
    "print(f\"R2 score : \", r2_score(y_predictions,y_train))\n",
    "print(f\"These are the model predictions : \", y_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
